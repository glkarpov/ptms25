{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95be0ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df69402",
   "metadata": {},
   "source": [
    "# Frequentist probability\n",
    "\n",
    "For some complex scenarios it may be impossible to know distribution law apriori. To get some insights we can use frequency approach: perform many experiments and define probability of event as the limit of its relative frequency to the total number of experiments.\n",
    "\n",
    "For example let us consider frequential experiment with the 6-sided die, as if we don't know probabilities of obtaining each side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e1a283",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_draws = 12000\n",
    "result = np.empty(n_draws)\n",
    "\n",
    "\n",
    "for i in range(n_draws):\n",
    "    result[i] = np.random.randint(1,7)    \n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(result, bins=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf568559",
   "metadata": {},
   "source": [
    "If we deal with continuous random variable we also can use histogram to at least approximate form of the density function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76b7b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = stats.norm(0, 1)\n",
    "\n",
    "# Find out global properties of population:\n",
    "mu = b.mean()\n",
    "var = b.var()\n",
    "\n",
    "# Generate Sample Means\n",
    "n_draws = 50000\n",
    "random_var = np.empty(n_draws)\n",
    "n_bins = 50\n",
    "\n",
    "for i in range(n_draws):\n",
    "    random_var[i] = np.random.normal(0, 1)   \n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(random_var, bins=n_bins).grid()\n",
    "counts, _, _ = plt.hist(random_var, bins=n_bins, alpha=0.0)  # just in order to find out the scaling coefficient for PDF\n",
    "plt.title('Histogram for standard normal variable')\n",
    "#     plt.axvline(x=np.mean(z), label='Mean of Sample Means')\n",
    "\n",
    "# scaling of normal PDF is needed, because histogram has large values on y-axis, and we need to fit them\n",
    "x_space = np.linspace(-5, 5)\n",
    "plt.plot(x_space, np.max(counts) * stats.norm.pdf(x_space, 0, 1) * np.sqrt(2 * np.pi), label='Normal density')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c17533d",
   "metadata": {},
   "source": [
    "# Central Limit Theorem\n",
    "\n",
    "Originally states that:\n",
    "\n",
    "Let $X_1, \\ldots, X_n$ be a sequence of independent random variables taken from the **same** distribution, i.e. all $X_i$'s have the same mean $\\mu$ and finite variance $\\sigma^2$. If we construct **new** random variable:\n",
    "\n",
    "$$\n",
    "W = \\frac{\\sum \\limits_{i=1}^{n} X_i - n \\mu}{\\sigma \\sqrt{n}},\n",
    "$$\n",
    "\n",
    "then its distribution tends to normal as $n \\rightarrow \\infty$: $W  \\rightarrow Z \\sim \\mathcal{N}(0,1)$.\n",
    "\n",
    "In other words:\n",
    "\n",
    "$$\n",
    "P \\left( W < a\\right) \\rightarrow \\Phi(a), \\; \\; n \\rightarrow \\infty.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2375f31e",
   "metadata": {},
   "source": [
    "### Once again, sum of many ANY random variables gives us.. normal?\n",
    "### Looks like cheap scam!\n",
    "\n",
    "To prove that let's take random variable that is **faaaar** from being normal.\n",
    "\n",
    "How the sum of them can at least remotely be normal? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87b8b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = stats.beta(0.05, 0.05)\n",
    "\n",
    "# Find out global properties of population:\n",
    "mu = b.mean()\n",
    "var = b.var()\n",
    "\n",
    "# Generate Sample Means\n",
    "n_draws = 10000\n",
    "random_var = np.empty(n_draws)\n",
    "n_bins = 20\n",
    "\n",
    "for i in range(n_draws):\n",
    "    random_var[i] = np.random.beta(0.05, 0.05)   \n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(random_var, bins=n_bins).grid()\n",
    "counts, _, _ = plt.hist(random_var, bins=n_bins, alpha=0.0)  # just in order to find out the scaling coefficient for PDF\n",
    "plt.title('Histogram for beta random variable')\n",
    "\n",
    "# scaling of normal PDF is needed, because histogram has large values on y-axis, and we need to fit them\n",
    "x_space = np.linspace(-3, 3)\n",
    "plt.plot(x_space, np.max(counts) * stats.norm.pdf(x_space, 0, 1) * np.sqrt(2 * np.pi), label='Normal density')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d4ac64",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.title('True density of beta random variable')\n",
    "\n",
    "# scaling of normal PDF is needed, because histogram has large values on y-axis, and we need to fit them\n",
    "x_space = np.linspace(-1, 3, 10000)\n",
    "plt.plot(x_space, b.pdf(x_space), label='beta density')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9ac669",
   "metadata": {},
   "source": [
    "## Just-as-theory form\n",
    "\n",
    "We introduce random variable $W$, such that:\n",
    "\n",
    "$$\n",
    "W = \\frac{\\sum X_i - n \\mu}{\\sigma \\sqrt{n}}\n",
    "$$\n",
    "\n",
    "And we check that $W \\sim \\mathcal{N}(0,1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f705554c",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = stats.beta(0.05, 0.05)\n",
    "\n",
    "# Find out global properties of population:\n",
    "bias = 1\n",
    "mu = b.mean() + bias\n",
    "sigma = np.sqrt(b.var())\n",
    "var = b.var()\n",
    "\n",
    "# Generate Sample Means\n",
    "n_draws = 10000\n",
    "x_totals = np.empty(n_draws)\n",
    "n_bins = 50\n",
    "\n",
    "for sample_size in range(1, 35):\n",
    "    for i in range(n_draws):\n",
    "        sample = b.rvs(size=sample_size) + bias\n",
    "        x_totals[i] = np.sum(sample)    \n",
    "    \n",
    "    z = (x_totals - sample_size * mu) / np.sqrt(var * sample_size)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.histplot(z, bins=n_bins).grid()\n",
    "    counts, _, _ = plt.hist(z, bins=n_bins, alpha=0.0)  # just in order to find out the scaling coefficient for PDF\n",
    "    plt.title(r'Approximate density shape of variable $W$ (sample size = {})'.format(sample_size))\n",
    "\n",
    "    # scaling of normal PDF is needed, because histogram has large values on y-axis, and we need to fit them\n",
    "    x_space = np.linspace(-5, 5)\n",
    "    plt.plot(x_space, np.max(counts) * stats.norm.pdf(x_space, 0, 1) * np.sqrt(2 * np.pi), label='Standard Normal')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d188dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "129c9f68",
   "metadata": {},
   "source": [
    "## Philosophical form\n",
    "\n",
    "You may notice that form of $W = \\frac{\\sum X_i - n \\mu}{\\sigma \\sqrt{n}}$ very looks like as if we make transformation to standard normal variable. If so, we also can reverse this transformation and look just at the variable $Y = \\sum \\limits_{i=1}^{n} X_i$.\n",
    "\n",
    "We await that:\n",
    "\n",
    "$$\n",
    "Y \\sim \\mathcal{N}(n \\mu, n \\sigma^2) \n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d610abec",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = stats.beta(0.05, 0.05)\n",
    "\n",
    "# Find out global properties of population:\n",
    "bias = 1\n",
    "mu = b.mean() + bias\n",
    "sigma = np.sqrt(b.var())\n",
    "var = b.var()\n",
    "\n",
    "print(\"Parameters of a single random variable: Mean = {}, Var = {}\".format(mu, var))\n",
    "\n",
    "# Generate Sample Means\n",
    "n_draws = 10000\n",
    "x_totals = np.empty(n_draws)\n",
    "n_bins = 50\n",
    "for sample_size in range(1, 35):\n",
    "    for i in range(n_draws):\n",
    "        sample = np.random.beta(0.05, 0.05, size=sample_size) + bias\n",
    "        x_totals[i] = np.sum(sample)    \n",
    "    \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.histplot(x_totals, bins=n_bins).grid()\n",
    "    counts, _, _ = plt.hist(x_totals, bins=n_bins, alpha=0.0)  # just in order to find out the scaling coefficient for PDF\n",
    "    if sample_size == 1:\n",
    "        plt.title(r'Approximate density shape of variable $(X_1)$')\n",
    "    else:\n",
    "        plt.title(r'Approximate density shape of variable $(X_1 + \\ldots + X_{%d})$' % (sample_size))\n",
    "    \n",
    "    # scaling of normal PDF is needed, because histogram has large values on y-axis, and we need to fit them\n",
    "    x_space = np.linspace(sample_size * mu - 3 * var * sample_size, sample_size * mu + 3 * var * sample_size, 1000)\n",
    "    current_std = np.sqrt(var * sample_size)\n",
    "    plt.plot(x_space, np.max(counts) * stats.norm.pdf(x_space, sample_size * mu, current_std) * np.sqrt(2 * np.pi) * current_std, label=r'$\\mathcal{N} \\; \\left(%s \\cdot %s, \\; %s \\sigma^2\\right)$' % (sample_size, mu, sample_size))\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fcf873",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c1409de8",
   "metadata": {},
   "source": [
    "## CLT for averages\n",
    "\n",
    "We also focus at another form which will be used a lot during Statistics course.\n",
    "\n",
    "Again we construct random variable $W$ as follows:\n",
    "\n",
    "$$\n",
    "W = \\frac{\\sum X_i - n \\mu}{\\sigma \\sqrt{n}}\n",
    "$$\n",
    "\n",
    "But now let's divide both numerator and denominator by $n$:\n",
    "\n",
    "$$\n",
    "W = \\frac{\\frac{\\sum X_i}{n} - \\mu}{\\frac{\\sigma}{\\sqrt{n}}}\n",
    "$$\n",
    "\n",
    "Again we can see that this looks like transformation of normal random variable $ M = \\frac{\\sum X_i}{n}$. In this case CLT also works, and provides connection to normal distribution.\n",
    "\n",
    "Below we check that $M \\sim \\mathcal{N} \\left(\\mu, \\frac{\\sigma^2}{n} \\right)$, where $M = \\frac{\\sum X_i}{n}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294166dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = stats.beta(0.05, 0.05)\n",
    "\n",
    "# Find out global properties of population:\n",
    "bias = 3\n",
    "mu = b.mean() + bias\n",
    "sigma = np.sqrt(b.var())\n",
    "var = b.var()\n",
    "\n",
    "print(\"Parameters of a single random variable: Mean = {}, Var = {}\".format(mu, var))\n",
    "\n",
    "n_draws = 5000\n",
    "x_means = np.empty(n_draws)\n",
    "n_bins = 50\n",
    "\n",
    "for sample_size in range(1, 50):\n",
    "    for i in range(n_draws):\n",
    "        sample = np.random.beta(0.05, 0.05, size=sample_size) + bias\n",
    "        x_means[i] = sample.mean()\n",
    "        \n",
    "    x_space = np.linspace(mu - 3 * var, mu + 3 * var, 1000)\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.histplot(x_means, bins=n_bins).grid()\n",
    "    counts, _, _ = plt.hist(x_means, bins=n_bins, alpha=0.0)  # just in order to find out the scaling coefficient for PDF\n",
    "\n",
    "    if sample_size == 1:\n",
    "        plt.title(r'Approximate density shape of variable $(X_1)$')\n",
    "    else:\n",
    "        plt.title(r'Approximate density shape of variable $\\frac{\\sum X_i}{%d}$' % (sample_size))\n",
    "\n",
    "    # scaling of normal PDF is needed, because histogram has large values on y-axis, and we need to fit them\n",
    "    current_std = np.sqrt(var / sample_size)\n",
    "    plt.plot(x_space, np.max(counts) * stats.norm.pdf(x_space, mu, current_std) * np.sqrt(2 * np.pi) * current_std, label=r'$\\mathcal{N} \\; \\left(%s, \\frac{\\sigma^2}{%s}\\right)$' % (mu, sample_size))\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a43807",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
