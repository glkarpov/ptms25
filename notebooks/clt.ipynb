{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95be0ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import randint, norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df69402",
   "metadata": {},
   "source": [
    "# Frequentist probability\n",
    "## _MÃ©thode de Monte-Carlo_\n",
    "For some complex scenarios it may be impossible to know distribution _a_ _priori_. To get some insights we can use frequency approach: perform many experiments and define probability of event as the limit of its relative frequency to the total number of experiments.\n",
    "\n",
    "For example let us consider frequential experiment with the 6-sided die, as if we don't know probabilities of obtaining each side."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf568559",
   "metadata": {},
   "source": [
    "If we deal with continuous random variable we also can use histogram to at least approximate form of the density function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e1a283",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_draws = 36000\n",
    "rv = randint(low=1,high=7)\n",
    "result = np.empty(n_draws)\n",
    "\n",
    "\n",
    "for i in range(n_draws):\n",
    "    result[i] = rv.rvs(1)[0]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31a92b6-2db6-4dc4-8e1b-33b0b3204016",
   "metadata": {},
   "source": [
    "In the same way we can try to analyze approximate form of the density function for continuous random variables.\n",
    "\n",
    "Since they have infinitely many values, we divide all available space in bins, and just compute how many times our random variable of interest fell in each bin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76b7b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = stats.norm(0, 1)\n",
    "\n",
    "# Find out global properties of population:\n",
    "mu = b.mean()\n",
    "var = b.var()\n",
    "\n",
    "# Generate Sample Means\n",
    "n_draws = 100000\n",
    "result = np.empty(n_draws)\n",
    "n_bins = 100\n",
    "\n",
    "for i in range(n_draws):\n",
    "    result[i] = b.rvs(1)[0]   \n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(result, bins=n_bins).grid()\n",
    "counts, _, _ = plt.hist(result, bins=n_bins, alpha=0.0)  # just in order to find out the scaling coefficient for PDF\n",
    "plt.title('Histogram for standard normal variable')\n",
    "\n",
    "# scaling of normal PDF is needed, because histogram has large values on y-axis, and we need to fit them\n",
    "x_space = np.linspace(-5, 5)\n",
    "plt.plot(x_space, np.max(counts) * stats.norm.pdf(x_space, 0, 1) * np.sqrt(2 * np.pi), label='Normal density')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47556d70-7f8b-4564-9648-12879d441a39",
   "metadata": {},
   "source": [
    "## Transition to the Central Limit Theorem: 2 dices\n",
    "\n",
    "Let us return to the first example with 6-sided dice.\n",
    "But for now suppose we have **2** independent dices and we now observe two random variables at once: discrete bivariate vector $(X,Y)$.\n",
    "\n",
    "New random variable $T = f(X,Y) = X + Y$ is clearly a function from $X$ and $Y$ and also is a random variables itself.\n",
    "It is possible to obtain its probability mass function (PMF) theoretically, but let us apply our simulation and see how the histogram looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08e302e-e096-43c7-bc61-1f3c4e39e4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_draws = 36000\n",
    "rv = randint(low=1,high=7)\n",
    "result = np.empty(n_draws)\n",
    "\n",
    "\n",
    "for i in range(n_draws):\n",
    "    x = rv.rvs(1)[0]\n",
    "    y = rv.rvs(1)[0]\n",
    "    result[i] = x + y\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef35a2d7-1693-453d-8c56-8e6c4ebcd5c7",
   "metadata": {},
   "source": [
    "## Transition to the Central Limit Theorem: 3 dices\n",
    "\n",
    "In this example we go even further and here we have **3** independent dices, which means we observe three random variables at once: discrete vector $(X_1, X_2, X_3)$.\n",
    "\n",
    "Again we are going to look at their sum - random variable $T = X_1 + X_2 + X_3$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1effce-7116-4464-8c04-d4cdd7394764",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_draws = 36000\n",
    "rv = randint(low=1,high=7)\n",
    "result = np.empty(n_draws)\n",
    "\n",
    "\n",
    "for i in range(n_draws):\n",
    "    x_1 = rv.rvs(1)[0]\n",
    "    x_2 = rv.rvs(1)[0]\n",
    "    x_3 = rv.rvs(1)[0]\n",
    "    result[i] = x_1 + x_2 + x_3\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1ea97b-bd30-4320-9aa3-dd7033aade4d",
   "metadata": {},
   "source": [
    "## Transition to the Central Limit Theorem: 5 dices\n",
    "\n",
    "In this example we go even further and here we have **5** independent dices, which means we observe five random variables at once: discrete vector $(X_1, X_2, X_3, X_4, X_5)$.\n",
    "\n",
    "Again we are going to look at their sum - random variable $T = X_1 + X_2 + X_3 + X_4 + X_5$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7c6dc7-4c94-4168-b1cd-e680230a97d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_draws = 60000\n",
    "rv = randint(low=1,high=7)\n",
    "result = np.empty(n_draws)\n",
    "\n",
    "\n",
    "for i in range(n_draws):\n",
    "    x_1 = rv.rvs(1)[0]\n",
    "    x_2 = rv.rvs(1)[0]\n",
    "    x_3 = rv.rvs(1)[0]\n",
    "    x_4 = rv.rvs(1)[0]\n",
    "    x_5 = rv.rvs(1)[0]\n",
    "    result[i] = x_1 + x_2 + x_3 + x_4 + x_5\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c17533d",
   "metadata": {},
   "source": [
    "# Central Limit Theorem\n",
    "\n",
    "## 'Philosophical' form\n",
    "- Let $X_1, \\ldots, X_n$ be a sequence of independent random variables taken from the **same** distribution, i.e. all $X_i$'s have the same expectation $\\mu$ and finite variance $\\sigma^2$. Let us construct **new** random variable:\n",
    "\n",
    "$$\n",
    "S_n = \\sum \\limits_{i=1}^{n} X_i.\n",
    "$$\n",
    "\n",
    "- According to the properties of expectation and variance, properties of the new random variable are:\n",
    "\n",
    "\\begin{gather}\n",
    "    E[S_n] = E \\Bigl[ \\sum \\limits_{i=1}^{n} X_i \\Bigr] = \\sum \\limits_{i=1}^{n} E[X_i] = n \\mu \\\\\n",
    "    Var[S_n] = Var \\Bigl[ \\sum \\limits_{i=1}^{n} X_i \\Bigr] = \\sum \\limits_{i=1}^{n} Var[X_i] = n \\sigma^2\n",
    "\\end{gather}\n",
    "\n",
    "- **Central Limit Theorem**: distribution of such random variable $S_n$ tends to normal as $n \\rightarrow \\infty$: $S_n  \\rightarrow  Y \\sim \\mathcal{N}(n \\mu, n \\sigma^2)$.\n",
    "More specifically formulated:\n",
    "\n",
    "$$\n",
    "  \\forall x \\in \\mathbb{R} \\quad  P(S_n < x) \\underset{n \\rightarrow \\infty}{\\longrightarrow} P(Y < x), \\text{ where } Y \\sim \\mathcal{N}(n \\mu, n \\sigma^2).\n",
    "$$\n",
    "\n",
    "- In simple words, we can just say that $S_n \\sim \\mathcal{N}(n \\mu, n \\sigma^2)$, when $n$ is sufficiently large."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2375f31e",
   "metadata": {},
   "source": [
    "### Once again, sum of many ANY random variables gives us.. normal?\n",
    "### Looks like cheap scam!\n",
    "\n",
    "To prove that let's take random variable that is **faaar** from being normal.\n",
    "\n",
    "How on Earth the density function of sum of them can at least remotely resemble normal distribution? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87b8b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = stats.beta(0.05, 0.05)\n",
    "\n",
    "# Find out global properties of population:\n",
    "mu = b.mean()\n",
    "var = b.var()\n",
    "\n",
    "# Generate Sample Means\n",
    "n_draws = 10000\n",
    "random_var = np.empty(n_draws)\n",
    "n_bins = 20\n",
    "\n",
    "for i in range(n_draws):\n",
    "    random_var[i] = np.random.beta(0.05, 0.05)   \n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(random_var, bins=n_bins).grid()\n",
    "counts, _, _ = plt.hist(random_var, bins=n_bins, alpha=0.0)  # just in order to find out the scaling coefficient for PDF\n",
    "plt.title('Histogram for beta random variable')\n",
    "\n",
    "# scaling of normal PDF is needed, because histogram has large values on y-axis, and we need to fit them\n",
    "x_space = np.linspace(-3, 3)\n",
    "plt.plot(x_space, np.max(counts) * stats.norm.pdf(x_space, 0, 1) * np.sqrt(2 * np.pi), label='Normal density')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d4ac64",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.title('True density of beta random variable')\n",
    "\n",
    "# scaling of normal PDF is needed, because histogram has large values on y-axis, and we need to fit them\n",
    "x_space = np.linspace(-1, 3, 10001)\n",
    "plt.plot(x_space, b.pdf(x_space), label='beta density')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8f95ce-26dc-439a-9fc7-855aa05ede7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = stats.beta(0.05, 0.05)\n",
    "\n",
    "# Find out global properties of population:\n",
    "bias = 1\n",
    "mu = b.mean() + bias\n",
    "sigma = np.sqrt(b.var())\n",
    "var = b.var()\n",
    "\n",
    "print(\"Parameters of a single random variable: Mean = {}, Var = {}\".format(mu, var))\n",
    "\n",
    "# Generate Sample Means\n",
    "n_draws = 100000\n",
    "x_totals = np.empty(n_draws)\n",
    "n_bins = 50\n",
    "for sample_size in range(1, 50):\n",
    "    for i in range(n_draws):\n",
    "        sample = np.random.beta(0.05, 0.05, size=sample_size) + bias\n",
    "        x_totals[i] = np.sum(sample)    \n",
    "    \n",
    "    plt.figure(figsize=(12, 3))\n",
    "    sns.histplot(x_totals, bins=n_bins).grid()\n",
    "    counts, _, _ = plt.hist(x_totals, bins=n_bins, alpha=0.0)  # just in order to find out the scaling coefficient for PDF\n",
    "    if sample_size == 1:\n",
    "        plt.title(r'Approximate density shape of variable $(X_1)$')\n",
    "    else:\n",
    "        plt.title(r'Approximate density shape of variable $(X_1 + \\ldots + X_{%d})$' % (sample_size))\n",
    "    \n",
    "    # scaling of normal PDF is needed, because histogram has large values on y-axis, and we need to fit them\n",
    "    x_space = np.linspace(sample_size * mu - 3 * var * sample_size, sample_size * mu + 3 * var * sample_size, 1000)\n",
    "    current_std = np.sqrt(var * sample_size)\n",
    "    plt.plot(x_space, np.max(counts) * stats.norm.pdf(x_space, sample_size * mu, current_std) * np.sqrt(2 * np.pi) * current_std, label=r'$\\mathcal{N} \\; \\left(%s \\cdot %s, \\; %s \\sigma^2\\right)$' % (sample_size, mu, sample_size))\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    # plt.savefig('plot_{}.png'.format(sample_size))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baede854-e20a-4c6f-a52a-54b5d426d51a",
   "metadata": {},
   "source": [
    "# Central Limit Theorem\n",
    "\n",
    "## More widespread formulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d2fad1-4fb4-4e1c-baed-7dd81a4c355b",
   "metadata": {},
   "source": [
    "More often in textbooks we can meet another formulation of CLT.\n",
    "\n",
    "Firstly, recall that if $X$ is any normal random variable, then the following function makes it _standard_ normal:\n",
    "\n",
    "$$\n",
    "    Z = \\frac{X - E[X]}{\\sqrt{Var[X]}}, \\quad Z \\sim \\mathcal{N}(0,1)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b360961e-5216-4242-88c5-75cb12a8a364",
   "metadata": {},
   "source": [
    "- Let $X_1, \\ldots, X_n$ be a sequence of independent random variables taken from the **same** distribution, i.e. all $X_i$'s have the same expectation $\\mu$ and finite variance $\\sigma^2$.\n",
    "- As before we construct **new** random variable:\n",
    "$$\n",
    "    S_n = \\sum \\limits_{i=1}^{n} X_i, \\quad E[S_n] = n \\mu, \\quad Var[S_n] = n \\sigma^2.\n",
    "$$\n",
    "\n",
    "- Let us apply tranformation to $S_n$:\n",
    "$$\n",
    "    Z_n = \\frac{S_n - E[S_n]}{\\sqrt{Var[S_n]}} = \\frac{S_n - n \\mu}{\\sigma \\sqrt{n}}\n",
    "$$\n",
    "- Properties of this new random variable:\n",
    "  \\begin{gather}\n",
    "    E[Z_n] = E \\Bigl[\\frac{S_n}{\\sigma \\sqrt{n}} - \\frac{n \\mu}{\\sigma \\sqrt{n}} \\Bigr] = E \\Bigl[\\frac{S_n}{\\sigma \\sqrt{n}} \\Bigl] - E \\Bigl[\\frac{n \\mu}{\\sigma \\sqrt{n}} \\Bigr] = \\frac{n \\mu}{\\sigma \\sqrt{n}} - \\frac{n \\mu}{\\sigma \\sqrt{n}} = 0 \\\\\n",
    "    Var[Z_n] = Var \\Bigl[\\frac{S_n}{\\sigma \\sqrt{n}} - \\frac{n \\mu}{\\sigma \\sqrt{n}} \\Bigr] = Var \\Bigl[\\frac{S_n}{\\sigma \\sqrt{n}} \\Bigl] + Var \\Bigl[\\frac{n \\mu}{\\sigma \\sqrt{n}} \\Bigr] = \\frac{Var[S_n]}{n \\sigma^2} + 0 = 1.\n",
    "  \\end{gather}\n",
    "- **Central Limit Theorem**: distribution of such random variable $Z_n$ tends to **standard** normal as $n \\rightarrow \\infty$: $Z_n  \\rightarrow  Z \\sim \\mathcal{N}(0, 1)$.\n",
    "\n",
    "- In simple words, if $n$ is large enough, then we can say that $S_n \\sim \\mathcal{N}(n \\mu, n \\sigma^2)$, and simultaneously random variable $Z_n = \\frac{S_n - n\\mu}{\\sigma \\sqrt{n}}$ has standard normal distribution _i.e._ $Z_n \\sim \\mathcal{N}(0, 1)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f705554c",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = stats.beta(0.05, 0.05)\n",
    "\n",
    "# Find out global properties of population:\n",
    "mu = b.mean()\n",
    "sigma = np.sqrt(b.var())\n",
    "var = b.var()\n",
    "\n",
    "# Generate Sample Means\n",
    "n_draws = 10000\n",
    "x_totals = np.empty(n_draws)\n",
    "n_bins = 50\n",
    "\n",
    "for sample_size in range(1, 35):\n",
    "    for i in range(n_draws):\n",
    "        sample = b.rvs(size=sample_size)\n",
    "        x_totals[i] = np.sum(sample)    \n",
    "\n",
    "    # transformation of all realizations to standard normal\n",
    "    z = (x_totals - sample_size * mu) / np.sqrt(var * sample_size)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.histplot(z, bins=n_bins).grid()\n",
    "    counts, _, _ = plt.hist(z, bins=n_bins, alpha=0.0)  # just in order to find out the scaling coefficient for PDF\n",
    "    plt.title(r'Approximate density shape of variable $Z_n$ (sample size = {})'.format(sample_size))\n",
    "\n",
    "    # scaling of standard normal PDF, because histogram has large values on y-axis, and we need to fit them\n",
    "    x_space = np.linspace(-5, 5)\n",
    "    plt.plot(x_space, np.max(counts) * stats.norm.pdf(x_space, 0, 1) * np.sqrt(2 * np.pi), label='Standard Normal')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
